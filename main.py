from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from typing_extensions import TypedDict
from langchain_core.messages import AnyMessage
from langgraph.graph import StateGraph
from langgraph.graph import START, END
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings
from typing_extensions import List, TypedDict
from langchain_core.documents import Document
from langchain import hub
from langchain_community.tools import TavilySearchResults
from typing import Literal
from langgraph.graph import END
from langchain_core.messages import ToolMessage
from typing import Union

from loan_tools import equal_principal_schedule, equal_payment_schedule, bullet_repayment_schedule

load_dotenv()


class AgentState(TypedDict):
    query: str
    context: List[Document]
    answer: str
    messages: List[AnyMessage]

prompt = hub.pull("rlm/rag-prompt")
llm = ChatOpenAI(model='gpt-4o')
tools = [equal_principal_schedule, equal_payment_schedule, bullet_repayment_schedule]
llm_with_tools = llm.bind_tools(tools)
embeddings = OpenAIEmbeddings(model='text-embedding-3-large')

def tool_node(state: AgentState) -> AgentState:
    # ë§ˆì§€ë§‰ ë©”ì‹œì§€ì—ì„œ tool_calls êº¼ë‚´ê¸°
    last_message = state['messages'][-1]
    tool_calls = last_message.tool_calls

    tool_messages = []

    for call in tool_calls:
        tool_name = call["name"]
        args = call["args"]
        
        # íˆ´ ì‹¤í–‰ (ToolNodeê°€ ì•„ë‹ˆê³  ì§ì ‘ ë§¤í•‘í•´ë„ OK)
        for tool in tools:
            if tool.name == tool_name:
                result = tool.invoke(args)
                break
        else:
            raise ValueError(f"Tool {tool_name} not found")

        # ToolMessage ìƒì„± ë° ì €ì¥
        tool_messages.append(ToolMessage(
            tool_call_id=call["id"],  # ë˜ëŠ” call["id"]
            content=str(result)
        ))

    # ìƒíƒœì— ToolMessage ì¶”ê°€
    state["messages"].extend(tool_messages)
    return state

vector_store = Chroma(
    embedding_function=embeddings,
    collection_name='document_collection',
    persist_directory='./document_collection'
)

retriever = vector_store.as_retriever(search_kwargs={'k': 3})

def retrieve(state: AgentState) -> AgentState:
    """
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ê¸°ë°˜í•˜ì—¬ ë²¡í„° ìŠ¤í† ì–´ì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.

    Args:
        state (AgentState): ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ í¬í•¨í•œ ì—ì´ì „íŠ¸ì˜ í˜„ì¬ state.

    Returns:
        AgentState: ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì¶”ê°€ëœ stateë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    query = state['query']  # stateì—ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    docs = retriever.invoke(query)  # ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.

    return {'context': docs}  # ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ í¬í•¨í•œ stateë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.


tavily_search_tool = TavilySearchResults(
    max_results=3,
    search_depth="advanced",
    include_answer=True,
    include_raw_content=True,
    include_images=True,
)

def agent(state:  AgentState) -> AgentState:
    """
    ì—ì´ì „íŠ¸ í•¨ìˆ˜ëŠ” ì£¼ì–´ì§„ ìƒíƒœì—ì„œ ë©”ì‹œì§€ë¥¼ ê°€ì ¸ì™€
    LLMê³¼ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ë©”ì‹œì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        state: ë©”ì‹œì§€ ìƒíƒœë¥¼ í¬í•¨í•˜ëŠ” state.

    Returns:
        MessagesState: ì‘ë‹µ ë©”ì‹œì§€ë¥¼ í¬í•¨í•˜ëŠ” ìƒˆë¡œìš´ state.
    """
    # ìƒíƒœì—ì„œ ë©”ì‹œì§€ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    messages = state['query']
    
    # LLMê³¼ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•˜ê³  ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    response = llm_with_tools.invoke(messages)
    
    # ì‘ë‹µ ë©”ì‹œì§€ë¥¼ ìƒˆë¡œìš´ ìƒíƒœë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    return {'messages': [response]}

def web_search(state: AgentState) -> AgentState:
    """
    ì£¼ì–´ì§„ stateë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

    Args:
        state (AgentState): ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ í¬í•¨í•œ ì—ì´ì „íŠ¸ì˜ í˜„ì¬ state.

    Returns:
        AgentState: ì›¹ ê²€ìƒ‰ ê²°ê³¼ê°€ ì¶”ê°€ëœ stateë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    query = state['query']
    results = tavily_search_tool.invoke(query)

    return {'context': results}


doc_relevance_prompt = hub.pull("langchain-ai/rag-document-relevance")
def check_doc_relevance(state: AgentState) -> Literal['relevant', 'irrelvant']:
    """
    ì£¼ì–´ì§„ stateë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¬¸ì„œì˜ ê´€ë ¨ì„±ì„ íŒë‹¨í•©ë‹ˆë‹¤.

    Args:
        state (AgentState): ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ë¬¸ë§¥ì„ í¬í•¨í•œ ì—ì´ì „íŠ¸ì˜ í˜„ì¬ state.

    Returns:
        Literal['relevant', 'irrelevant']: ë¬¸ì„œê°€ ê´€ë ¨ì„±ì´ ë†’ìœ¼ë©´ 'relevant', ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ 'irrelevant'ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    query = state['query']
    context = state['context']

    doc_relevance_chain = doc_relevance_prompt | llm
    response = doc_relevance_chain.invoke({'question': query, 'documents': context})

    if response['Score'] == 1:
        return 'relevant'
    
    return 'irrelvant'


def generate(state: AgentState) -> AgentState:
    """
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        state (AgentState): ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ í¬í•¨í•œ ì—ì´ì „íŠ¸ì˜ í˜„ì¬ state.

    Returns:
        AgentState: ìƒì„±ëœ ì‘ë‹µì´ ì¶”ê°€ëœ stateë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    context = state['context'] + state["messages"]  # stateì—ì„œ ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    query = state['query']  # stateì—ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    rag_chain = prompt | llm   # RAG í”„ë¡¬í”„íŠ¸ì™€ LLMì„ ì—°ê²°í•˜ì—¬ ì²´ì¸ì„ ë§Œë“­ë‹ˆë‹¤.
    response = rag_chain.invoke({'question': query, 'context': context})  # ì§ˆë¬¸ê³¼ ë¬¸ë§¥ì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    return {'answer': response}  # ìƒì„±ëœ ì‘ë‹µì„ í¬í•¨í•œ stateë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

def check_finance_related(state: AgentState) -> Literal["finance", "non_finance"]:
    """
    ì‚¬ìš©ìì˜ queryê°€ ê¸ˆìœµ ê´€ë ¨ì¸ì§€ íŒë³„í•˜ì—¬ 'finance' ë˜ëŠ” 'non_finance' ë¬¸ìì—´ì„ ë°˜í™˜.
    retrieval ì´ì „ ë‹¨ê³„ì—ì„œ í˜¸ì¶œí•˜ë¯€ë¡œ contextëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ.
    """
    query = state["query"]

    system_msg = (
        "You are a strict binary classifier. "
        "Return exactly one token: finance or non_finance."
        "Finance includes: banking, loans, deposits, interest rates, cards, investments, "
        "stocks, bonds, funds, FX, crypto (as financial asset), insurance, taxes on financial assets, "
        "financial regulations/compliance, personal finance, corporate finance."
        "Non-finance includes: weather, travel tips (non-cost), general tech, cooking, sports scores, etc."
    )
    user_msg = f"Query: {query}\nAnswer with only: finance or non_finance"

    resp = llm.invoke([("system", system_msg), ("user", user_msg)])
    label = (resp.content or "").strip().lower()

    if label.startswith("finance"):
        return "finance"
    else:
        # ì¢…ë£Œ ì´ìœ ë¥¼ stateì— ê¸°ë¡
        state["answer"] = "í•´ë‹¹ ì§ˆë¬¸ì€ ê¸ˆìœµ ê´€ë ¨ì´ ì•„ë‹ˆì–´ì„œ ì²˜ë¦¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
        return "non_finance"


def notify_non_finance(state: AgentState) -> AgentState:
    reason = state.get("answer", "í•´ë‹¹ ì§ˆë¬¸ì€ ê¸ˆìœµ ê´€ë ¨ì´ ì•„ë‹ˆì–´ì„œ ì²˜ë¦¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    return {"answer": reason}



def should_continue(state: AgentState) -> Literal['tools', "retrieve"]:
    """
    ì£¼ì–´ì§„ ë©”ì‹œì§€ ìƒíƒœë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì—ì´ì „íŠ¸ê°€ ê³„ì† ì§„í–‰í• ì§€ ì—¬ë¶€ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.

    Args:
        state (MessagesState): `state`ë¥¼ í¬í•¨í•˜ëŠ” ê°ì²´.

    Returns:
        Literal['tools', END]: ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ë©´ `tools`ë¥¼ ë¦¬í„´í•˜ê³ , 
        ë‹µë³€í•  ì¤€ë¹„ê°€ ë˜ì—ˆë‹¤ë©´ ENDë¥¼ ë°˜í™˜í•´ì„œ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.
    """
    # ìƒíƒœì—ì„œ ë©”ì‹œì§€ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    messages = state['messages']
    
    # ë§ˆì§€ë§‰ AI ë©”ì‹œì§€ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    last_ai_message = messages[-1]
    
    # ë§ˆì§€ë§‰ AI ë©”ì‹œì§€ê°€ ë„êµ¬ í˜¸ì¶œì„ í¬í•¨í•˜ê³  ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
    if last_ai_message.tool_calls:
        print("ğŸ” Tool Calls Detected:")
        for call in last_ai_message.tool_calls:
            print(f"- Tool Name: {call['name']}")
            print(f"- Arguments: {call['args']}")

        feedback = input("ğŸ‘ ì´ tool í˜¸ì¶œì´ ì ì ˆí•œê°€ìš”? (y/n): ")
        if feedback.lower() == "y":
            return "tools"
        else:
            return "agent"
    
    # ë„êµ¬ í˜¸ì¶œì´ ì—†ìœ¼ë©´ retrieveë¡œ ë„˜ì–´ê°€ ê´€ë ¨ ë¬¸ì„œë“¤ì„ ì°¸ì¡°í•©ë‹ˆë‹¤.
    return "retrieve"

graph_builder = StateGraph(AgentState)
graph_builder.add_node('retrieve', retrieve)
graph_builder.add_node('generate', generate)
graph_builder.add_node('web_search', web_search)
graph_builder.add_node('check_doc_relevance', check_doc_relevance)
graph_builder.add_node('check_finance_related', check_finance_related)
graph_builder.add_node("notify_non_finance", notify_non_finance)
graph_builder.add_node('agent', agent)
graph_builder.add_node('tools', tool_node)

graph_builder.add_conditional_edges(
    START,
    check_finance_related,
    {
        "finance": "agent",       # ê¸ˆìœµì´ë©´ agent í˜¸ì¶œ
        "non_finance": "notify_non_finance"  # ë¹„ê¸ˆìœµì´ë©´ ì¦‰ì‹œ ì¢…ë£Œ
    }
)

graph_builder.add_conditional_edges(
    'agent',
    should_continue,
    ['tools', "agent", "retrieve"]  # ë„êµ¬ í˜¸ì¶œì´ ìˆìœ¼ë©´ 'tools'ë¡œ, ì—†ìœ¼ë©´ 'retrieve'ë¡œ ì´ë™
)
graph_builder.add_edge('tools', 'retrieve')

graph_builder.add_conditional_edges(
    'retrieve',
    check_doc_relevance,
    {
        'relevant': 'generate',
        'irrelvant': 'web_search'
    }
)
# graph_builder.add_edge('rewrite', 'web_search')
graph_builder.add_edge('web_search', 'generate')
graph_builder.add_edge('generate', END)
graph_builder.add_edge('notify_non_finance', END)

graph = graph_builder.compile()

from pathlib import Path

# Mermaid ê¸°ë°˜ PNG ì´ë¯¸ì§€ ë°”ì´íŠ¸ ìƒì„±
png_bytes = graph.get_graph().draw_mermaid_png()

# íŒŒì¼ë¡œ ì €ì¥
output_path = Path("graph_structure.png")
with open(output_path, "wb") as f:
    f.write(png_bytes)

print(f"ê·¸ë˜í”„ êµ¬ì¡° PNG ì €ì¥ ì™„ë£Œ: {output_path}")


query = "ì›ê¸ˆ 1ì²œë§Œì›, ì—° 6%, 24ê°œì›” ë™ì•ˆ ì›ê¸ˆê· ë“±ìœ¼ë¡œ ìƒí™˜í•  ì‹œ ë‚´ëŠ” ê¸ˆì•¡ì´ ì–¼ë§ˆì§€"
initial_state = {'query': query}
result = graph.invoke(initial_state)
print(result['answer'])  # ìƒì„±ëœ ì‘ë‹µì„ ì¶œë ¥í•©ë‹ˆë‹¤.